# -*- coding: utf-8 -*-
"""Brain_detector.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gHVu6o5mU1VXiECdCk_uhdkwMrwf5Lro
"""



"""## Comparative Study of Conventional Machine Learning and Deep Learning Models in MRI Image-based Brain Tumor Detection

### Research Questions

1. What are the differences between conventional machine learning models and convolutional neural networks (CNNs) and transfer learning models while detecting brain tumors using MRI images?
2. Would enhanced Transfer Learning enhance perfomance when compaired to traditional and raw cnn models?
3. To what extent do the models match real labels, as indicated by kappa score and other metrics of evaluation?

### Working Approach
For the development of the project, My main goal will be to compaire the performance of various machine learning models under this reseach in detecting brain tumors from MRI images. The model categrories to be compaired will be:

- Traditional models i.e  Logistic Regression (linear model) and Decision Tree (non-linear tree based model)
- Deep learning like
    - Handcrafted Convolutional Neural Network (CNN)
    - Pre-trained transfer learning models
        - VGG16
        - ResNet50

I will perfom image processing like scaling, transfoming, histogram equalization etc with the main goal being to  improve feature visibility and classification efficiency. All models will be tested for accuracy, F1-score, and Cohen's kappa metrics to measure prediction agreement with true ground truth labels. The  work aims to find out which methodology offers the best performance-reliability tradeoff, especially in clinical diagnostic scenarios.

### Data Information
- Dataset source - https://figshare.com/articles/dataset/brain_tumor_dataset/1512427
- Documentation - https://figshare.com/articles/dataset/brain_tumor_dataset/1512427?file=51340418
- Data Type - Matlab Images
- Classes - has classes like **glioma**, **meningioma** and **pituitary tumors**
- Who published the data -  The data were Authored and published by **Jun Cheng** [*dataset posted on 2024-12-21, 15:57 authored by Jun Cheng*]
- When -  First published online on **2024-12-21 , 15:57**

"""



import os, glob, random, cv2
import zipfile
import shutil
import warnings

import numpy as np
import pandas as pd


# plotting
import matplotlib
import seaborn as sns
import matplotlib.pyplot as plt
from PIL import Image, ImageFile
import matplotlib.patches as mpatches
from mpl_toolkits.mplot3d import Axes3D



# for reading mat files
import h5py
from tqdm import tqdm
from scipy.io import loadmat
from collections import Counter
from skimage.measure import regionprops, label as label_mask_ftn

from sklearn.decomposition import PCA
from sklearn.model_selection import train_test_split

# modelling
import torch
import torchvision
import torch.nn as nn
import torch.optim as optim
from torch.nn import functional as F
from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler
from torchvision import datasets, models, transforms

# classical models
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from xgboost import XGBClassifier


# metrics
from sklearn.metrics import (
    accuracy_score, precision_score,
    confusion_matrix, f1_score, classification_report,
    recall_score, cohen_kappa_score, roc_curve, auc
)

# processing
from sklearn.preprocessing import label_binarize, LabelEncoder


warnings.filterwarnings('ignore')
matplotlib.style.use('ggplot')
sns.set(style="whitegrid")

# For reproducibility
seed = 27
random.seed(seed)
os.environ['PYTHONHASHSEED'] = str(seed)
np.random.seed(seed)
torch.manual_seed(seed)
torch.cuda.manual_seed(seed)







!wget --user-agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36" https://figshare.com/ndownloader/articles/1512427/versions/8



# delete and recreate the ./process directory in order to avoid overwriting
if os.path.exists("./process"):
    shutil.rmtree("./process")
os.makedirs("./process", exist_ok=True)
print("Recreated './process' folder.")

# unzip the donloaded file into ./process
if os.path.exists("8") and zipfile.is_zipfile("8"):
    with zipfile.ZipFile("8", 'r') as zip_ref:
        zip_ref.extractall("./process")
    print("Unzipped '8' into './process'.")
else:
    print("File '8' not found or is not a ZIP file.")

os.listdir("./process")

!cat "./process/README 2024.txt"

# lets get the target zips we want
ZIP_FILE_NAMES = [
    'brainTumorDataPublic_2299-3064.zip',
    'brainTumorDataPublic_767-1532.zip',
    'brainTumorDataPublic_1533-2298.zip',
    'brainTumorDataPublic_1-766.zip'
]
ZIP_FILE_NAMES

# recreate ./process/mat to store unzipped mat images
mat_dir = "./process/mat"
if os.path.exists(mat_dir):
    shutil.rmtree(mat_dir)
os.makedirs(mat_dir, exist_ok=True)
print("Recreated './process/mat' folder.")

for zip_path in ZIP_FILE_NAMES:
    full_zip_path = os.path.join("./process", zip_path)
    with zipfile.ZipFile(full_zip_path, 'r') as zip_ref:
        zip_ref.extractall(mat_dir)
    print(f"Extracted {zip_path} into './process/mat'.")

# lets get the file extracted and know they are how many
mat_files = glob.glob("./process/mat/**/*.mat", recursive=True)


print(f"Total .mat iamge files in './process/mat': {len(mat_files)}")

random_file = random.choice(mat_files)

with h5py.File(random_file, 'r') as f:
    print(f"Keys in {random_file}:")
    print(list(f.keys()))

    #data
    cjdata = f['cjdata']

    label_data = cjdata['label']
    label = int(label_data[()][0][0])
    print("label is", label)

    image_data = cjdata['image']
    image_np = image_data[()]

    print("image shape is", image_np.shape)

    mask = cjdata['tumorMask'][()]

    print("Mask Shape is ", mask.shape)

#  a function to process the files
# The processing is an extract from the readme file above
def process_mat_files(input_path, output_path="./processed_data"):
    """
    convert .mat files to image and mask files, and returns a df
    with columns: ['image_path', 'mask_path', 'label']
    """
    os.makedirs(output_path, exist_ok=True)
    image_path = os.path.join(output_path, "images")
    mask_path = os.path.join(output_path, "masks")
    os.makedirs(image_path, exist_ok=True)
    os.makedirs(mask_path, exist_ok=True)

    mat_files = glob.glob(os.path.join(input_path, "*.mat"))
    records = []

    for mat_file in tqdm(mat_files, desc="Processing .mat files"):
        try:
            with h5py.File(mat_file, 'r') as f:
                cjdata = f['cjdata']

                # get the image and convert to uint8
                image = cjdata['image'][()]
                image = (255 * (image - np.min(image)) / (np.max(image) - np.min(image))).astype(np.uint8)

                # get the mask for tumor
                #we are doing just classification, the mask will be for visualization part
                mask = cjdata['tumorMask'][()].astype(np.uint8) * 255

                # label
                label = int(cjdata['label'][()][0][0])

                # create filenames
                base_name = os.path.splitext(os.path.basename(mat_file))[0]
                img_file_path = os.path.join(image_path, f"{base_name}.png")
                mask_file_path = os.path.join(mask_path, f"{base_name}_mask.png")

                # save them
                Image.fromarray(image).save(img_file_path)
                Image.fromarray(mask).save(mask_file_path)

                # keep record
                records.append({
                    'image_path': img_file_path,
                    'mask_path': mask_file_path,
                    'label': label
                })
        except Exception as e:
            print(f"Failed to process {mat_file}: {e}")
    df = pd.DataFrame(records)
    return df

df = process_mat_files(input_path="./process/mat")

!rm -r ./8*
!rm -r ./process

df.head()

# rename 1 for meningioma, 2 for glioma, 3 for pituitary tumor

label_mapping_to_name = {
    1: "meningioma",
    2: "glioma",
    3: "pituitary tumor"
}

# create a new column for label names
df["label_name"] = df["label"].map(label_mapping_to_name)
df.head()



# lets check the distribution of labels
labels, lbl_counts = np.unique(df["label"], return_counts=True)


# the labels and also color
label_names = ['Meningioma', 'Glioma', 'Pituitary Tumor']
colors = ['#0072B2', '#D55E00', '#F0E442']

# plot piue chart
plt.figure(figsize=(8, 8))
plt.pie(lbl_counts,
        labels=label_names,
        colors=colors,
        autopct='%1.1f%%',
        startangle=90, textprops={'fontsize': 12})
plt.title("Brain Tumor Type Distribution", fontsize=16, weight='bold')
plt.axis('equal')
plt.show()



# sample out some random imgs
sample_df = df.sample(n=18, random_state=42).reset_index(drop=True)

plt.figure(figsize=(16, 8))
for i in range(18):
    image_path = sample_df.loc[i, 'image_path']
    mask_path = sample_df.loc[i, 'mask_path']
    label = str(sample_df.loc[i, 'label_name'])
    #read the images
    image = np.array(Image.open(image_path))
    mask = np.array(Image.open(mask_path)) > 0 #supposed to be boolena

    # do a plot
    plt.subplot(3, 6, i + 1)
    plt.imshow(image, cmap='bone')

    # make black in mask as transparent--Nothing
    masked = np.ma.masked_where(mask == False, mask)
    plt.imshow(masked, alpha=0.3, cmap='autumn')

    plt.title(label, fontsize=10)
    plt.axis('off')

plt.suptitle("Brain Tumor Samples with Masks", fontsize=16, fontweight="bold")
plt.tight_layout(rect=[0, 0, 1, 0.96])
plt.show()



"""---
# Exploratory Analysis of Brain Tumor Images
The main goal for the anasysis is to be able to identify whether there are distinguishable characteristics that can be used to differentiate the tumors. It will main be quantifying the most relevant features in images
We are going to extract and analyze a set of morphological and intensity-based features from the tumor regions. This will help in informations like tumor size, shape, intersity, patterns etcs of the 3 tumor types we have.


## Features Extracted and Their Relevance
- Tumor Size (`tumor_size`) -  The total number of pixels that the tumor occupies in the mask. It represents tumor volumnn in 2d slice which can be used to show tumor growth and how severe it is

- Tumor Area (`tumor_area`) - It is calculated  by the region properties function, similar to tumor size, which is the area of the contiguous tumor area.

- Tumor Perimeter (`tumor_perimeter`) - The border perimeter of the tumor. It helps in accessing tumor complexity and irregularity i.e those tumor which are more irregular (on boarders) have larger perimeter.

- Eccentricity (`eccentricity`) - Measures how elongated the tumor shape is, with 0 being a perfect circle and values approaching 1 indicating more elongated shapes. Help recognize tumors based on shape.

- Solidity (`solidity`) - Ratio between the area of the tumor and the area of the convex hull of the tumor. It defines how "compact" or "filled" the tumor area is, indicating shape irregularities such as indentations or concavities.

- Aspect Ratio (`aspect_ratio`) - This is the ratio of the width to the height of the tumor bounding box. It shows shape elongation of the tumor

- Mean Intensity (`mean_intensity`) - The average pixel intensity of the tumor region. SHows how bright/contrast the tumor tissues are in the MRI slice.

- Standard Deviation of Intensity (`std_intensity`) - It shows how variable the pixel intensity within the tumor.  The higher the value, the more hetegorogenous the tumor is.

Through extraction of these features on a representative subsample of the dataset (we sample in order to get the representation of the images population as well as utilize available resouses well by using less resources for extraction), It helps provide more detailed analysis and visualization of statistical comparison that will identify characteristic patterns between tumor types.
It is necessary to provide a foundation for later stages, including classification modeling and clinical interpretation.

---
"""

tumor_stats = []

# we will just use about 1k images
SAMPLE_SIZE = 1000
sample_df = df.sample(SAMPLE_SIZE, random_state=2025)
# iterate through the images
for _, row in tqdm(sample_df.iterrows(), total=len(sample_df)):
    image = np.array(Image.open(row['image_path']))
    mask = np.array(Image.open(row['mask_path'])) > 0
    if mask.sum() == 0:
        continue  # skip empty masks

    # get region properties
    labeled_mask = label_mask_ftn(mask)
    props = regionprops(labeled_mask)

    if len(props) == 0:
        continue

    #I'm assuming no image has more than 1 tumor.
    #  In this case we just analysise one tumor per image
    region = props[0]

    minr, minc, maxr, maxc = region.bbox
    width = maxc - minc
    height = maxr - minr
    aspect_ratio = width / height if height > 0 else 0


    tumor_stats.append({
        'label': row['label'],
        'label_name': row['label_name'],
        'tumor_size': mask.sum(),
        'tumor_area': region.area,
        'tumor_perimeter': region.perimeter,
        'eccentricity': region.eccentricity,
        'mean_intensity': image[mask].mean(),
        'std_intensity': image[mask].std(),
        'centroid_y': region.centroid[0],
        'centroid_x': region.centroid[1],
        'solidity': region.solidity,
        'aspect_ratio': aspect_ratio,

    })
stat_df = pd.DataFrame(tumor_stats)

stat_df.head()

stat_df.describe().T

"""# I. Dimensionality Reduction using PCA
In this case, through the use of PCA, we are trying to check if the flattened features can vusually split the different tumor types
"""

# get a sample data and run pca and plot
X = np.stack([np.array(Image.open(p).resize((128, 128))).flatten() for p in sample_df.image_path])
y = sample_df.label.values

# create 2d so that we can easily plot
X_pca = PCA(n_components=2).fit_transform(X)

# plot
plt.figure(figsize=(8, 8))
sns.scatterplot(x=X_pca[:, 0], y=X_pca[:, 1], hue=sample_df.label_name, palette="Set1")
plt.title("PCA of Brain Tumor Images", fontweight="bold")
plt.show()

"""As it can be observed `pituitary tumor` seems to be very distint from the other two. It also have extreme values (this is based on principal values)

### II. Tumor Size by Class
- This helps shows which tumor appears bigger/has more pixels on average than the other
"""

# plot a box plot for this
plt.figure(figsize=(10, 6))
sns.boxplot(data=stat_df, x='label_name', y='tumor_size', palette='Set2')
plt.title('Tumor Size Distribution by Class')
plt.ylabel('Tumor Size (pixels)')
plt.xlabel('Tumor Type')
plt.xticks(rotation=15)
plt.tight_layout()
plt.show()

"""### Mean Intensity Inside Tumor"""

plt.figure(figsize=(10, 6))
sns.violinplot(data=stat_df, x='label_name', y='mean_intensity', palette='Set3')
plt.title('Mean Intensity Inside Tumor Region')
plt.ylabel('Mean Intensity')
plt.xlabel('Tumor Type')
plt.xticks(rotation=15)
plt.tight_layout()
plt.show()



"""### III.  Tumor Eccentricity Comparison
- shows how elongated the tumor is (0 = circle, 1 = line)
"""

plt.figure(figsize=(10, 6))
sns.violinplot(data=stat_df, x='label_name', y='eccentricity', palette='Set2')
plt.title('Tumor Eccentricity by Class')
plt.ylabel('Eccentricity (0 = round, 1 = line-like)')
plt.xlabel('Tumor Type')
plt.xticks(rotation=15)
plt.tight_layout()
plt.show()



"""### IV. Tumor Perimeter Comparison
- Shows how the length of tumor boundary is compaired with others
"""

plt.figure(figsize=(10, 6))
sns.boxplot(data=stat_df, x='label_name', y='tumor_perimeter', palette='Pastel1')
plt.title('Tumor Perimeter by Class')
plt.ylabel('Perimeter (pixels)')
plt.xlabel('Tumor Type')
plt.xticks(rotation=15)
plt.tight_layout()
plt.show()

"""### V. Tumor Aspect Ratio Comparison
- Its Width/Height of bounding box measurement
"""

plt.figure(figsize=(10, 6))
sns.boxplot(data=stat_df, x='label_name', y='aspect_ratio', palette='Set3')
plt.title('Tumor Aspect Ratio (Width / Height) by Class')
plt.ylabel('Aspect Ratio')
plt.xlabel('Tumor Type')
plt.xticks(rotation=15)
plt.tight_layout()
plt.show()



"""### VI. Solidity Comparison (shape fill-ness)
Shows how the Area / Convex Hull Area or how filled the shape is
"""

plt.figure(figsize=(10, 6))
sns.boxplot(data=stat_df, x='label_name', y='solidity', palette='coolwarm')
plt.title('Tumor Solidity by Class')
plt.ylabel('Solidity (area / convex area)')
plt.xlabel('Tumor Type')
plt.xticks(rotation=15)
plt.tight_layout()
plt.show()



"""### VII. Pixel Intensity Histograms by Class

"""

# plot intensity distribution for the masks
plt.figure(figsize=(12, 6))
for label in [1, 2, 3]:
    class_images = sample_df[sample_df.label == label]
    pixels = []
    for _, row in class_images.iterrows():
        img = np.array(Image.open(row["image_path"]))
        mask = np.array(Image.open(row["mask_path"])) > 0
        pixels.extend(img[mask])

    sns.histplot(pixels, label=label_mapping_to_name[label], kde=True, stat='density', bins=50)

plt.title("Pixel Intensity Distributions Within Tumor Regions")
plt.xlabel("Pixel Intensity")
plt.ylabel("Density")
plt.legend()
plt.tight_layout()
plt.show()





"""### VIII. Tumor Location Heatmap
This shows where tumors tend to appear in image space.
"""

# get a size to resizes our images to
target_size = (256, 256)
heatmap = np.zeros(target_size, dtype=np.float32)
for _, row in sample_df.iterrows():
    mask = Image.open(row['mask_path']).convert('L').resize(target_size)
    mask = np.array(mask) > 0
    heatmap += mask.astype(np.float32)

plt.figure(figsize=(16, 16))
plt.imshow(heatmap, cmap='hot')
plt.title(f"Tumor Location Heatmap (Resized to {target_size})", fontweight="bold", fontsize=17)
plt.colorbar(label='Tumor Occurrence Frequency')
plt.xlabel("X (Pixels)")
plt.ylabel("Y (Pixels)")
plt.grid(False)
plt.show()





"""---
#### Data Splitting Methodology
The data is going to be divided into three subsets which does not overlap which are:
- Training subset (60%) - Which will be the main split used for training the model
- validation subset (20%) - For tuning model hyperparameters and overfitting checking. This is used during the training process/validates the model
- Test Set (20%) - For final model testing and evaluations. This is what we will used to get perfomance metrics

The split will be performed in two phases with **stratified sampling** to maintain the **class distributions** (meningioma, glioma, pituitary tumor) across all subsets as folows;
1. **First Split** -  60% of data was allocated to the training set, and the other 40% was kept temporarily separate.
2. **Second Split** - This is a temporary split which is divided equally into the validation and test sets (each 20% of the total data).
This approach ensures the model to be trained and tested on various data and finally tested on **fully unseen** instances, which is critical in measuring real-world generalization.
"""

df.head()

# we need to relabel our labels such that it starts from 0......n since current it starts from 1----n
lbl_encoder = LabelEncoder()

df["y"] = lbl_encoder.fit_transform(df['label_name'])

df.y.unique(), df.label.unique()

df.head()

# perform the first split 60:40
train_df, temp_df = train_test_split(
    df,
    test_size=0.4,
    stratify=df.label,
    random_state=2025
)

# get the 40% split  into 20% val and 20% test
val_df, test_df = train_test_split(
    temp_df,
    test_size=0.5,
    stratify=temp_df.label,
    random_state=2025
)


print(
    f"""
Train Size {train_df.shape}  --> {len(train_df)/len(df):.4f}
Test Size {test_df.shape} --> {len(test_df)/len(df):.4f}
Val Size {val_df.shape} -->  {len(val_df)/len(df):.4f}
    """
)

train_df.head()



# some parameters
# This are defined here so as to be used globally by all our models
class TRAINING_PARAMS:
    BATCH_SIZE = 32
    DEVICE = torch.device("cuda:0" if torch.cuda.is_available() else "cpu:0")
    NUM_CLASSES = 3
    EPOCH_NUM = 10
    IMG_DIM = 224

# data processort class
# Helps in custom loading our dataset using torch dataset class so as we can create a data loader
class BrainMRIDataset(Dataset):
    def __init__(self, df, transform=None):
        self.df = df
        self.transform = transform

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        #this is where we have the loading process.
        # Our models needs also to have the labels from 0-n, thats why we are using the Y column we created.
        # If we use the 1-n, it will raise errors i.e we have 3 classes. To avoid this we might need to put 4 classes.
        selected_img_record = self.df.iloc[idx]
        img_path = f"{selected_img_record['image_path']}"
        image = Image.open(img_path).convert('RGB')
        if self.transform:
            image = self.transform(image)

        return image, selected_img_record["y"]

# transformation will involve
    #  resize to 224 by 224 (default size for resnet and vgg models)
    #  normalize pixels

mri_transformation = transforms.Compose([
    transforms.Resize((TRAINING_PARAMS.IMG_DIM, TRAINING_PARAMS.IMG_DIM)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# create the datasets
train_data = BrainMRIDataset(df=train_df, transform=mri_transformation)
val_data = BrainMRIDataset(df=val_df, transform=mri_transformation)
test_data = BrainMRIDataset(df=test_df, transform=mri_transformation)

# check if the dataset is created
test_data[0]



# a data loader for loading the data while during training
train_loader = DataLoader(train_data, batch_size=TRAINING_PARAMS.BATCH_SIZE, shuffle=True)
val_loader = DataLoader(val_data, batch_size=TRAINING_PARAMS.BATCH_SIZE, shuffle=False)
test_loader = DataLoader(test_data, batch_size=TRAINING_PARAMS.BATCH_SIZE, shuffle=False)

# checking if the data loaders wirks
# It is batched to batch size we had
for pxl,lbl, in test_loader:
    print(lbl, pxl.shape)
    break;

# see if we can feed the gpu
lbl.long().to(TRAINING_PARAMS.DEVICE)
#
# torch.tensor(lbl, dtype=torch.long).to(TRAINING_PARAMS.DEVICE)

# training functions
# a way to track and aggregate performance metrics
class PerformanceLogger:
    """
    Helps calculate the training metrics per epoch.
    """
    def __init__(self):
        self.initialize()
    def initialize(self):
        self.current_loss, self.current_accuracy = 0, 0
        self.total_loss, self.total_accuracy = 0, 0
        self.average_loss, self.average_accuracy = 0, 0
        self.sample_count = 0
        self.actuals = []
        self.predictions = []

    def record(self, loss, accuracy, predicted, actual, batch_size=1):
        self.current_loss = loss
        self.current_accuracy = accuracy
        self.total_loss += loss * batch_size
        self.total_accuracy += accuracy * batch_size
        self.sample_count += batch_size

        self.average_loss = self.total_loss / self.sample_count
        self.average_accuracy = self.total_accuracy / self.sample_count

        self.actuals.extend(actual.cpu().numpy())
        self.predictions.extend(predicted.cpu().numpy())

    def get_f1(self):
        return f1_score(self.actuals, self.predictions, average='weighted')


# to store logs for both training and validation steps
class MetricsHistory:
    """
    Helps keep track of all logs that we have
    """
    def __init__(self):
        self.train_losses = []
        self.train_accuracies = []
        self.train_f1_scores = []
        self.validation_losses = []
        self.validation_accuracies = []
        self.validation_f1_scores = []

    def update(self, training_stats, validation_stats):
        self.train_losses.append(training_stats.average_loss)
        self.train_accuracies.append(training_stats.average_accuracy)
        self.train_f1_scores.append(training_stats.get_f1())
        self.validation_losses.append(validation_stats.average_loss)
        self.validation_accuracies.append(validation_stats.average_accuracy)
        self.validation_f1_scores.append(validation_stats.get_f1())


# ftn to perform training for a single epoch
def train_one_epoch(loader, model, optimizer, loss_fn, device, current_epoch):
    """
    Run a signle training epoch with the model
    """
    model.train()
    epoch_metrics = PerformanceLogger()
    progress_bar = tqdm(loader, total=len(loader))

    for batch_idx, (inputs, targets) in enumerate(progress_bar):
        #print(f"Batch {batch_idx} loaded.")
        #print("Targets:", targets)
        #print("Unique target values:", torch.unique(targets))

        inputs = inputs.to(device)
        targets = targets.to(device)

        optimizer.zero_grad()
        outputs = model(inputs)
        loss = loss_fn(outputs, targets)

        preds = torch.argmax(outputs, dim=1)
        accuracy = (preds == targets).sum().item() / targets.size(0)

        loss.backward()
        optimizer.step()

        epoch_metrics.record(loss.item(), accuracy, preds, targets, batch_size=targets.size(0))
        progress_bar.set_postfix(
            train_loss=epoch_metrics.average_loss,
            train_accuracy=epoch_metrics.average_accuracy,
            train_f1=epoch_metrics.get_f1(),
            epoch=current_epoch + 1
        )

    return epoch_metrics


# ftn to evaluate the model on validation data
def evaluate_model(loader, model, loss_fn, device, current_epoch):
    """
    Evaluating the model during training. We keep track of evaluation metrics
    """
    model.eval()
    val_metrics = PerformanceLogger()
    progress_bar = tqdm(loader, total=len(loader))

    with torch.no_grad():
        for batch_idx, (inputs, targets) in enumerate(progress_bar):
            inputs = inputs.to(device)
            targets = targets.to(device)

            outputs = model(inputs)
            loss = loss_fn(outputs, targets)

            preds = torch.argmax(outputs, dim=1)
            accuracy = (preds == targets).sum().item() / targets.size(0)

            val_metrics.record(loss.item(), accuracy, preds, targets, batch_size=targets.size(0))
            progress_bar.set_postfix(
                val_loss=val_metrics.average_loss,
                val_accuracy=val_metrics.average_accuracy,
                val_f1=val_metrics.get_f1(),
                epoch=current_epoch + 1
            )

    return val_metrics

# a fulll training loop that manages training and validation over multiple epochs
def run_training_pipeline(model, model_id, train_data, val_data, optimizer, loss_function, total_epochs=10, device='cuda'):
    """This does the whole training of the models using the loggers and functions above"""
    # Initialize metric history storage
    history = MetricsHistory()
    top_f1_score = 0.0

    for epoch_index in range(total_epochs):
        # train model for one epoch
        training_stats = train_one_epoch(train_data, model, optimizer, loss_function, device, epoch_index)
        # run validation of the model after training epoch
        validation_stats = evaluate_model(val_data, model, loss_function, device, epoch_index)
        #updated the params
        history.update(training_stats, validation_stats)
        # save the best models using f1 scores as params
        current_f1 = validation_stats.get_f1()
        if current_f1 > top_f1_score:
            top_f1_score = current_f1
            torch.save(model.state_dict(), f'{model_id}_best_model.pth')

    print(f"Training finished. Highest validation F1 score: {top_f1_score:.4f}")
    return history



"""---

### Deep Learning Models (CNN, VGG16, Resnet50)
- Includes
    - VGG16 pretrained model
    - Resnet50 pretrained model
    - CNN model created.


This is the modeling part of this project. In thi case,  we will use some deep learning models to detect brain tumors from MRI images. Deep learning models learn automatically from data, specifically from complex images, without any manually carried out feature specifications. The following are the models that we have utilized:

#### VGG16 (Pretrained)
VGG16 is a deep learning model, which is initially trained on millions of ordinary daily photos (of the ImageNet dataset). Since it has already "learned" shapes, edges, and textures, we repurpose this learning to learn features of brain tumors in MRI images. This method is called **transfer learning**—we **transfer** learned knowledge from one task (an already learned model) to another (brain tumor detection), more quickly and accurately.

#### ResNet50 (Pretrained)

ResNet50 is another pretrained model that is supposed to be deeper than VGG16 through the use of shortcut connections (residual links) to maintain it from being affected by vanishing gradients. ResNet50 is pretrained on the ImageNet dataset too. Just as with VGG16, we transform it to suit our medical task through its depth as well as its capability to extract training learned features.

#### Custom CNN Model

Apart from the pretrained models, I will also implement a **Convolutional Neural Network (CNN)** from scratch. The modelis will be trained end-to-end directly from the brain MRI dataset. It does not utilize prior knowledge, but it offers full architecture control and is trained end-to-end on tumor classification task. We can edit the aarchitecture


Every deep learning model above has its own strength and characteristics. The Pretrained models offer speed and accuracy with less training data, while the custom CNN provides flexibility and is tailored specifically to our dataset.

---

#### 1. VGG16 Model.
"""

# the vgg16 model implimentation from pretrained.
# we just modify the top layer to allow it to match the number of classes we have.
# the other weights are going to remain.
class BrainMRIVGGClassifier(nn.Module):
    def __init__(self, num_classes):
        super(BrainMRIVGGClassifier, self).__init__()
        #loading the pretrained weights (pretrained with imagenet images)
        self.feature_extractor = models.vgg16_bn(pretrained=True)
        # remove the last classification layer. This is what we are going to replace
        self.feature_extractor.classifier = nn.Sequential(*list(self.feature_extractor.classifier.children())[:-1])
        #we create the new classification head, with 3 classes we have
        self.classifier_head = nn.Linear(4096, num_classes)
        #results should be probs
        self.probability_output = nn.Softmax(dim=1)

    def forward(self, input_tensor):
        features = self.feature_extractor(input_tensor)
        flattened = features.view(features.size(0), -1)
        logits = self.classifier_head(flattened)
        probabilities = self.probability_output(logits)
        return probabilities

# create an instance of the model
vgg_mri_model = BrainMRIVGGClassifier(num_classes=TRAINING_PARAMS.NUM_CLASSES).to(TRAINING_PARAMS.DEVICE)

# opt and loss ftn to be used during the training
optimizer = optim.Adam(vgg_mri_model.parameters(), lr=1e-4)
loss_function = nn.CrossEntropyLoss()

# do the training for the model
vgg_training_history = run_training_pipeline(
    model=vgg_mri_model,
    model_id="VGG_MRI_Model",
    train_data=train_loader,
    val_data=val_loader,
    optimizer=optimizer,
    loss_function=loss_function,
    total_epochs=TRAINING_PARAMS.EPOCH_NUM,
    device=TRAINING_PARAMS.DEVICE
)

# after training we can visualize how the model was learning.
# this function uses the metric logs we created to d a visualization
def plot_models_training_metrics(metrics_history, model_name="Model"):
    """
    vizs training and validation performance metrics across epochs.
    """
    metrics = [
        ("Loss", metrics_history.train_losses, metrics_history.validation_losses, "red", "orange"),
        ("Accuracy", metrics_history.train_accuracies, metrics_history.validation_accuracies, "green", "blue"),
        ("F1 Score", metrics_history.train_f1_scores, metrics_history.validation_f1_scores, "purple", "brown")
    ]

    fig, axes = plt.subplots(1, 3, figsize=(21, 7))

    def plot_metric(ax, train_vals, val_vals, metric_label, color_train, color_val):
        ax.plot(train_vals, marker='o', label=f'{metric_label} (Train)', color=color_train, linewidth=2)
        ax.plot(val_vals, marker='o', label=f'{metric_label} (Validation)', color=color_val, linewidth=2)
        ax.set_title(f'{metric_label} Per Epoch', fontsize=13, fontweight='bold')
        ax.set_xlabel('Epoch', fontsize=11)
        ax.set_ylabel(metric_label, fontsize=11)
        ax.legend()
        ax.grid(True)

    for ax, (name, train, val, c_train, c_val) in zip(axes, metrics):
        plot_metric(ax, train, val, name, c_train, c_val)

    fig.suptitle(f'{model_name} Training Performance Summary', fontsize=16, fontweight='bold')
    plt.tight_layout(rect=[0, 0, 1, 0.95])
    plt.show()

plot_models_training_metrics(vgg_training_history, "VGG16")

# this create predictions using the model
def generate_predictions(model, data_loader, device):
    """
    create model's predictions on the provided dataset.
    """
    model.eval()
    predictions = []
    true_labels = []
    with torch.no_grad():
        for batch in tqdm(data_loader, desc="Evaluating on test dataset..."):
            inputs, targets = batch
            outputs = model(inputs.to(device))

            predictions.extend(outputs.cpu().numpy())
            true_labels.extend(targets.cpu().numpy())

    return np.array(true_labels), np.array(predictions)

# load the best weights which were saved
def load_model(model_template, model_id, checkpoint_path, device=TRAINING_PARAMS.DEVICE):
    """
    load the model weights
    """
    model_template.load_state_dict(torch.load(f"{model_id}{checkpoint_path}", map_location=device))
    model_template.to(device)
    print(f"{model_id} model loaded successfully to {device} and set to evaluation mode.")
    return model_template



# functions to do evaluation.
# In this case we are going to plot Consfusion matric and also roc curve.
# we also have other metrics like f1, accruacy etc
def print_classification_summary(y_true, y_pred, class_labels, model_name):
    print(f"\n--- Classification Metrics Summary for **{model_name}** ---\n")
    print(f"Accuracy Score     : {accuracy_score(y_true, y_pred):.4f}")
    print(f"Precision Score    : {precision_score(y_true, y_pred, average='micro'):.4f}")
    print(f"Recall Score       : {recall_score(y_true, y_pred, average='micro'):.4f}")
    print(f"F1 Score           : {f1_score(y_true, y_pred, average='micro'):.4f}")
    print(f"Cohen's Kappa      : {cohen_kappa_score(y_true, y_pred):.4f}")
    print(f"\nDetailed Classification Report for **{model_name}**:\n")
    print(classification_report(y_true, y_pred, target_names=class_labels))

def plot_roc_curve(y_true, y_scores, class_labels, ax):
    fpr, tpr, _ = roc_curve(y_true, y_scores)
    roc_auc = auc(fpr, tpr)
    ax.plot(fpr, tpr, color='darkblue', lw=2, label=f"AUC = {roc_auc:.2f}")
    ax.plot([0, 1], [0, 1], linestyle='--', color='gray', lw=1)
    ax.set_xlim([0.0, 1.0])
    ax.set_ylim([0.0, 1.05])
    ax.set_xlabel('False Positive Rate', fontsize=11)
    ax.set_ylabel('True Positive Rate', fontsize=11)
    ax.set_title(f'ROC Curve: {class_labels[1]} vs {class_labels[0]}', fontsize=13, fontweight='bold')
    ax.legend(loc="lower right", fontsize=10)
    ax.grid(True)



def plot_roc_curve_multiclass(y_true, y_proba, class_labels, ax):
    n_classes = len(class_labels)

    # lets binarie the true labels
    y_true_bin = label_binarize(y_true, classes=list(range(n_classes)))
    for i in range(n_classes):
        fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_proba[:, i])
        roc_auc = auc(fpr, tpr)
        ax.plot(fpr, tpr, lw=2, label=f"{class_labels[i]} (AUC = {roc_auc:.2f})")

    ax.plot([0, 1], [0, 1], linestyle='--', color='gray', lw=1)
    ax.set_xlim([0.0, 1.0])
    ax.set_ylim([0.0, 1.05])
    ax.set_xlabel('False Positive Rate', fontsize=11)
    ax.set_ylabel('True Positive Rate', fontsize=11)
    ax.set_title("Multi-Class ROC Curve", fontsize=13, fontweight='bold')
    ax.legend(loc="lower right", fontsize=9)
    ax.grid(True)


def display_model_evaluation(y_true, y_probabilities, model_name, class_labels):
    print(f"\n===== Evaluation Results for {model_name} =====")
    y_pred = np.argmax(y_probabilities, axis=1)
    # show classification metrics
    print_classification_summary(y_true, y_pred, class_labels, model_name)
    #do the plots
    fig, axes = plt.subplots(1, 2, figsize=(16, 6))
    fig.suptitle(f'{model_name} - Evaluation Metrics & Confusion Matrix', fontsize=16, fontweight='bold')
    #roc
    plot_roc_curve_multiclass(y_true, y_probabilities, class_labels, axes[0])
    # cm
    cm = confusion_matrix(y_true, y_pred)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,
                xticklabels=class_labels, yticklabels=class_labels, ax=axes[1])
    axes[1].set_title("Confusion Matrix", fontsize=13, fontweight='bold')
    axes[1].set_xlabel("Predicted Label", fontsize=11)
    axes[1].set_ylabel("True Label", fontsize=11)
    axes[1].tick_params(axis='x', rotation=45)
    axes[1].tick_params(axis='y', rotation=0)
    plt.tight_layout(rect=[0, 0, 1, 0.93])
    plt.show()



# get the trained model
vgg_mri_model = load_model(
    model_template=vgg_mri_model,
    model_id = "VGG_MRI_Model",
    checkpoint_path='_best_model.pth',
    device=TRAINING_PARAMS.DEVICE)

# generate predictions for the models
vgg_labels, vgg_preds = generate_predictions(vgg_mri_model, test_loader, TRAINING_PARAMS.DEVICE)

display_model_evaluation(
    vgg_labels,
    vgg_preds,
    model_name="VGG16",
    class_labels=lbl_encoder.classes_.tolist()
)

# a function to visualize sample images after training the model
# Main purpose it to see how the model predicted
def visualize_predictions_with_model(df, model, class_names, device, model_name, num_samples=18):
    model.eval()
    sample_df = df.sample(n=num_samples, random_state=42).reset_index(drop=True)
    plt.figure(figsize=(18, 9))
    for i in range(num_samples):
        image_path = sample_df.loc[i, 'image_path']
        label = str(sample_df.loc[i, 'label_name'])
        mask = None
        if 'mask_path' in sample_df.columns:
            mask_path = sample_df.loc[i, 'mask_path']
            mask = np.array(Image.open(mask_path)) > 0

        # load the image
        image = Image.open(image_path).convert("RGB")
        image_np = np.array(image)
        #use same transformation used during training
        image_tensor = mri_transformation(image).unsqueeze(0).to(device)

        with torch.no_grad():
            outputs = model(image_tensor)
            probs = torch.softmax(outputs, dim=1).cpu().numpy()[0]
            pred_idx = np.argmax(probs)
            pred_label = class_names[pred_idx]
            pred_conf = probs[pred_idx]

        # Plotting
        plt.subplot(int(np.ceil(num_samples / 6)), 6, i + 1)
        plt.imshow(image_np, cmap='bone')

        # overlay mask
        if mask is not None:
            masked = np.ma.masked_where(mask == False, mask)
            plt.imshow(masked, alpha=0.3, cmap='autumn')

        plt.title(f"True: {label}\nPred: {pred_label} ({pred_conf:.2f})", fontsize=9, fontweight="bold", color="red")
        plt.axis("off")

    plt.suptitle(f"{model_name} model Predictions on Sample Brain MRI Images", fontsize=16, fontweight="bold")
    plt.tight_layout(rect=[0, 0, 1, 0.95])
    plt.show()

visualize_predictions_with_model(
    test_df,
    vgg_mri_model,
    lbl_encoder.classes_.tolist(),
    TRAINING_PARAMS.DEVICE,
    model_name = "VGG16"
)

"""#### 2. Resnet50 Model."""

# Modelling resnet50
class BrainMRIResNet50Classifier(nn.Module):
    def __init__(self, num_classes):
        super(BrainMRIResNet50Classifier, self).__init__()

        # load the pretrained resnet50 weights from imagenet
        self.base_model = models.resnet50(pretrained=True)

        # freeze the early layers
        # for param in self.base_model.parameters():
        #     param.requires_grad = False

        # replace the last FC layer with a customer layer that has 3 classes
        in_features = self.base_model.fc.in_features
        self.base_model.fc = nn.Sequential(
            nn.Linear(in_features, 512),
            nn.ReLU(),
            nn.Dropout(0.4),
            nn.Linear(512, num_classes),
            nn.Softmax(dim=1)
        )
    def forward(self, x):
        return self.base_model(x)

# create an instance for restnet50
resnet_mri_model = BrainMRIResNet50Classifier(
    num_classes=TRAINING_PARAMS.NUM_CLASSES
).to(TRAINING_PARAMS.DEVICE)

# optimizer and loss ftn
resnet_optimizer = optim.Adam(resnet_mri_model.parameters(), lr=1e-4)
resnet_loss_function = nn.CrossEntropyLoss()

# do the training
resnet_training_history = run_training_pipeline(
    model=resnet_mri_model,
    model_id="RESNET_MRI_Model",
    train_data=train_loader,
    val_data=val_loader,
    optimizer=resnet_optimizer,
    loss_function=resnet_loss_function,
    total_epochs=TRAINING_PARAMS.EPOCH_NUM,
    device=TRAINING_PARAMS.DEVICE
)

# plts
plot_models_training_metrics(resnet_training_history, "RESNET50")

# load the best trained model
resnet_mri_model = load_model(
    model_template=resnet_mri_model,
    model_id = "RESNET_MRI_Model",
    checkpoint_path='_best_model.pth',
    device=TRAINING_PARAMS.DEVICE)

# get predictions for test set
resnet_labels, resnet_preds = generate_predictions(resnet_mri_model, test_loader, TRAINING_PARAMS.DEVICE)

# plot evaluation
display_model_evaluation(
    resnet_labels,
    resnet_preds,
    model_name="RESNET50",
    class_labels=lbl_encoder.classes_.tolist()
)

visualize_predictions_with_model(
    test_df,
    resnet_mri_model,
    lbl_encoder.classes_.tolist(),
    TRAINING_PARAMS.DEVICE,
    model_name = "RESNET50"
)

"""#### 3. CNN Model."""

# create a cnn model
class BrainMRICNNClassifier(nn.Module):
    def __init__(self, img_dims, num_classes=3):
        super(BrainMRICNNClassifier, self).__init__()

        #We create few convolution bloacks so as to achieve better results.
        # Did manual testing to come up with a better one

        self.conv_block1 = nn.Sequential(
            nn.Conv2d(3, 16, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.Conv2d(16, 16, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2)
        )
        self.conv_block2 = nn.Sequential(
            nn.Conv2d(16, 32, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.Conv2d(32, 32, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.BatchNorm2d(32),
            nn.MaxPool2d(kernel_size=2, stride=2)
        )
        self.conv_block3 = nn.Sequential(
            nn.Conv2d(32, 64, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.Conv2d(64, 64, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.BatchNorm2d(64),
            nn.MaxPool2d(kernel_size=2, stride=2)
        )
        self.conv_block4 = nn.Sequential(
            nn.Conv2d(64, 128, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.Conv2d(128, 128, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.BatchNorm2d(128),
            nn.MaxPool2d(kernel_size=2, stride=2),
            nn.Dropout(0.2)
        )
        self.conv_block5 = nn.Sequential(
            nn.Conv2d(128, 256, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.Conv2d(256, 256, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.BatchNorm2d(256),
            nn.MaxPool2d(kernel_size=2, stride=2),
            nn.Dropout(0.2)
        )
        flattened_size = 256 * (img_dims // 32) * (img_dims // 32)

        # this is the final layer which is Fully connected.
        # We defined final results as a softmax to get probs
        self.fc_layers = nn.Sequential(
            nn.Flatten(),
            nn.Linear(flattened_size, 512),
            nn.ReLU(),
            nn.Dropout(0.7),
            nn.Linear(512, 128),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(64, num_classes),
            nn.Softmax(dim=1)
        )

    def forward(self, x):
        x = self.conv_block1(x)
        x = self.conv_block2(x)
        x = self.conv_block3(x)
        x = self.conv_block4(x)
        x = self.conv_block5(x)
        x = self.fc_layers(x)
        return x

# initialize cnn model
cnn_mri_model = BrainMRICNNClassifier(
    img_dims=TRAINING_PARAMS.IMG_DIM,
    num_classes=TRAINING_PARAMS.NUM_CLASSES
).to(TRAINING_PARAMS.DEVICE)

# loss and optimizer
cnn_optimizer = optim.Adam(cnn_mri_model.parameters(), lr=1e-4)
cnn_loss_function = nn.CrossEntropyLoss()

# do the training
cnn_training_history = run_training_pipeline(
    model=cnn_mri_model,
    model_id="CNN_MRI_Model",
    train_data=train_loader,
    val_data=val_loader,
    optimizer=cnn_optimizer,
    loss_function=cnn_loss_function,
    total_epochs=TRAINING_PARAMS.EPOCH_NUM,
    device=TRAINING_PARAMS.DEVICE
)

# plot the metrics progress
plot_models_training_metrics(cnn_training_history, "CNN_Model")

# load the best trained model
cnn_mri_model = load_model(
    model_template=cnn_mri_model,
    model_id = "CNN_MRI_Model",
    checkpoint_path='_best_model.pth',
    device=TRAINING_PARAMS.DEVICE)

# get predictions for test set
cnn_labels, cnn_preds = generate_predictions(cnn_mri_model, test_loader, TRAINING_PARAMS.DEVICE)

# plot evaluation
display_model_evaluation(
    cnn_labels,
    cnn_preds,
    model_name="CNN_Model",
    class_labels=lbl_encoder.classes_.tolist()
)

visualize_predictions_with_model(
    test_df,
    cnn_mri_model,
    lbl_encoder.classes_.tolist(),
    TRAINING_PARAMS.DEVICE,
    model_name = "CNN"
)